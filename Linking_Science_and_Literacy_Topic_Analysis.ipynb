{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1745746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"Exit_slip.csv\",engine='python',encoding='cp1252',na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Drop rows where 'Confused about' column has blanks; Replace 'Confused about' with 'learned' in this cell and all subsequent \n",
    "cells if generating topics using the text within the 'learned' column''' \n",
    "df = df[df['Confused about'].str.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea06405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# Function to check if a string contains only punctuation\n",
    "def is_only_punctuation(text):\n",
    "    return all(char in string.punctuation for char in text)\n",
    "# Remove rows where 'Confused about' contains only punctuation\n",
    "df = df[~df['Confused about'].apply(is_only_punctuation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb60cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "df['Confused_about'] = df['Confused about'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2bb7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuations, stopwords from 'Confused about' and lemmatize text\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "data = df.Confused_about.values.tolist()\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:1])\n",
    "import nltk \n",
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['vape','vaping','Vape','Vapes','Vaping','vaped','vapes','vapeing','confused','confuse'])\n",
    "import spacy \n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags and len(token)>3])\n",
    "    return texts_out\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "data_lemmatized = lemmatization(data_words_nostops, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'] )\n",
    "print(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06813fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bow corpus\n",
    "dictionary = gensim.corpora.Dictionary(data_lemmatized)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in data_lemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a672c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal no. of topics using Coherence score\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=1):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model=gensim.models.LdaMulticore(bow_corpus, num_topics=num_topics, id2word=dictionary,random_state=0)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=data_lemmatized, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=bow_corpus, texts=data_lemmatized, start=2, limit=40, step=1)\n",
    "limit=40; start=2; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ca404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd54189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate topics based on the no. of optimal topics which is '7' in this case \n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=7, id2word=dictionary,random_state=0)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81113869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find dominant topic in each sentence of the text\n",
    "def format_topics_sentences(ldamodel=lda_model, corpus=bow_corpus, texts=data_lemmatized):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "     # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=bow_corpus, texts=data_lemmatized)\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94507a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51f7ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word cloud for documents belonging to first topic\n",
    "df_1 = df_dominant_topic[df_dominant_topic['Dominant_Topic'] ==0] \n",
    "text_1=df_1['Text']\n",
    "text_1_st=text_1.to_string()\n",
    "wordcloud = WordCloud(max_words=50,background_color='#FFFFFF').generate(text_1_st)\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f01d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word cloud for documents belonging to second topic\n",
    "df_2 = df_dominant_topic[df_dominant_topic['Dominant_Topic'] ==1] \n",
    "text_2=df_2['Text']\n",
    "text_2_st=text_2.to_string()\n",
    "wordcloud = WordCloud(max_words=50,background_color='#FFFFFF').generate(text_2_st)\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13724398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word cloud for documents belonging to third topic\n",
    "df_3 = df_dominant_topic[df_dominant_topic['Dominant_Topic'] ==2] \n",
    "text_3=df_3['Text']\n",
    "text_3_st=text_3.to_string()\n",
    "wordcloud = WordCloud(max_words=50,background_color='#FFFFFF').generate(text_3_st)\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909835f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word cloud for documents belonging to fourth topic\n",
    "df_4 = df_dominant_topic[df_dominant_topic['Dominant_Topic'] ==3] \n",
    "text_4=df_4['Text']\n",
    "text_4_st=text_4.to_string()\n",
    "wordcloud = WordCloud(max_words=50,background_color='#FFFFFF').generate(text_4_st)\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ec61b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word cloud for documents belonging to fifth topic\n",
    "df_5 = df_dominant_topic[df_dominant_topic['Dominant_Topic'] ==4] \n",
    "text_5=df_5['Text']\n",
    "text_5_st=text_5.to_string()\n",
    "wordcloud = WordCloud(max_words=50,background_color='#FFFFFF').generate(text_5_st)\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d3225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word cloud for documents belonging to sixth topic\n",
    "df_6 = df_dominant_topic[df_dominant_topic['Dominant_Topic'] ==5] \n",
    "text_6=df_6['Text']\n",
    "text_6_st=text_6.to_string()\n",
    "wordcloud = WordCloud(max_words=50,background_color='#FFFFFF').generate(text_6_st)\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d8a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word cloud for documents belonging to seventh topic\n",
    "df_7 = df_dominant_topic[df_dominant_topic['Dominant_Topic'] ==6] \n",
    "text_7=df_1['Text']\n",
    "text_7_st=text_7.to_string()\n",
    "wordcloud = WordCloud(max_words=50,background_color='#FFFFFF').generate(text_7_st)\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
